#!/usr/bin/env python3
"""
å›¾ç‰‡åˆ†æå·¥å…· - åˆ†æOCRå¤±è´¥çš„åŸå› å¹¶æä¾›ä¼˜åŒ–å»ºè®®
"""

import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
import os
from pathlib import Path


class ImageAnalyzer:
    """å›¾ç‰‡è´¨é‡åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å›¾ç‰‡åˆ†æå™¨"""
        self.analysis_results = {}
    
    def analyze_image(self, image_path: str) -> Dict:
        """å…¨é¢åˆ†æå›¾ç‰‡è´¨é‡å’Œç‰¹å¾"""
        try:
            # è¯»å–å›¾ç‰‡
            img = cv2.imread(image_path)
            if img is None:
                return {'error': 'æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶'}
            
            # åŸºæœ¬ä¿¡æ¯
            height, width = img.shape[:2]
            channels = img.shape[2] if len(img.shape) > 2 else 1
            file_size = os.path.getsize(image_path)
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if channels > 1:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img
            
            # åˆ†æç»“æœ
            analysis = {
                'basic_info': {
                    'width': width,
                    'height': height,
                    'channels': channels,
                    'pixels': width * height,
                    'file_size_mb': file_size / (1024 * 1024),
                    'aspect_ratio': width / height if height > 0 else 0
                },
                'quality_metrics': self._analyze_quality(gray),
                'content_analysis': self._analyze_content(gray),
                'preprocessing_suggestions': [],
                'ocr_difficulty': 'unknown'
            }
            
            # ç”Ÿæˆé¢„å¤„ç†å»ºè®®
            analysis['preprocessing_suggestions'] = self._generate_suggestions(analysis)
            
            # è¯„ä¼°OCRéš¾åº¦
            analysis['ocr_difficulty'] = self._assess_ocr_difficulty(analysis)
            
            return analysis
            
        except Exception as e:
            return {'error': f'å›¾ç‰‡åˆ†æå¤±è´¥: {e}'}
    
    def _analyze_quality(self, gray_img: np.ndarray) -> Dict:
        """åˆ†æå›¾ç‰‡è´¨é‡æŒ‡æ ‡"""
        try:
            # äº®åº¦ç»Ÿè®¡
            mean_brightness = np.mean(gray_img)
            brightness_std = np.std(gray_img)
            
            # å¯¹æ¯”åº¦åˆ†æ
            contrast = brightness_std
            
            # æ¸…æ™°åº¦åˆ†æï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
            laplacian_var = cv2.Laplacian(gray_img, cv2.CV_64F).var()
            
            # ç›´æ–¹å›¾åˆ†æ
            hist = cv2.calcHist([gray_img], [0], None, [256], [0, 256])
            hist_peak = np.argmax(hist)
            hist_spread = np.std(np.where(hist > hist.max() * 0.1)[0])
            
            # è¾¹ç¼˜å¯†åº¦
            edges = cv2.Canny(gray_img, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            
            return {
                'mean_brightness': float(mean_brightness),
                'brightness_std': float(brightness_std),
                'contrast': float(contrast),
                'sharpness': float(laplacian_var),
                'hist_peak': int(hist_peak),
                'hist_spread': float(hist_spread),
                'edge_density': float(edge_density)
            }
            
        except Exception as e:
            return {'error': f'è´¨é‡åˆ†æå¤±è´¥: {e}'}
    
    def _analyze_content(self, gray_img: np.ndarray) -> Dict:
        """åˆ†æå›¾ç‰‡å†…å®¹ç‰¹å¾"""
        try:
            # æ–‡æœ¬åŒºåŸŸæ£€æµ‹ï¼ˆç®€å•æ–¹æ³•ï¼‰
            # ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ£€æµ‹å¯èƒ½çš„æ–‡æœ¬åŒºåŸŸ
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            
            # äºŒå€¼åŒ–
            _, binary = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # å½¢æ€å­¦æ“ä½œ
            morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # åˆ†æè½®å»“ç‰¹å¾
            text_like_regions = 0
            total_text_area = 0
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # è¿‡æ»¤å°åŒºåŸŸ
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = w / h if h > 0 else 0
                    
                    # åˆ¤æ–­æ˜¯å¦åƒæ–‡æœ¬åŒºåŸŸ
                    if 0.1 < aspect_ratio < 20 and area > 500:
                        text_like_regions += 1
                        total_text_area += area
            
            # è®¡ç®—æ–‡æœ¬åŒºåŸŸå æ¯”
            text_area_ratio = total_text_area / gray_img.size
            
            return {
                'total_contours': len(contours),
                'text_like_regions': text_like_regions,
                'text_area_ratio': float(text_area_ratio),
                'binary_threshold': int(cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0])
            }
            
        except Exception as e:
            return {'error': f'å†…å®¹åˆ†æå¤±è´¥: {e}'}
    
    def _generate_suggestions(self, analysis: Dict) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆé¢„å¤„ç†å»ºè®®"""
        suggestions = []
        
        try:
            quality = analysis.get('quality_metrics', {})
            content = analysis.get('content_analysis', {})
            basic = analysis.get('basic_info', {})
            
            # äº®åº¦é—®é¢˜
            brightness = quality.get('mean_brightness', 128)
            if brightness < 80:
                suggestions.append('å›¾ç‰‡è¿‡æš—ï¼Œå»ºè®®å¢åŠ äº®åº¦')
            elif brightness > 200:
                suggestions.append('å›¾ç‰‡è¿‡äº®ï¼Œå»ºè®®é™ä½äº®åº¦')
            
            # å¯¹æ¯”åº¦é—®é¢˜
            contrast = quality.get('contrast', 50)
            if contrast < 30:
                suggestions.append('å¯¹æ¯”åº¦è¿‡ä½ï¼Œå»ºè®®å¢å¼ºå¯¹æ¯”åº¦')
            elif contrast > 100:
                suggestions.append('å¯¹æ¯”åº¦è¿‡é«˜ï¼Œå»ºè®®ä½¿ç”¨è‡ªé€‚åº”å¤„ç†')
            
            # æ¸…æ™°åº¦é—®é¢˜
            sharpness = quality.get('sharpness', 100)
            if sharpness < 50:
                suggestions.append('å›¾ç‰‡æ¨¡ç³Šï¼Œå»ºè®®ä½¿ç”¨é”åŒ–æ»¤æ³¢')
            
            # å°ºå¯¸é—®é¢˜
            pixels = basic.get('pixels', 0)
            if pixels < 100000:  # å°äº100kåƒç´ 
                suggestions.append('å›¾ç‰‡å°ºå¯¸è¿‡å°ï¼Œå»ºè®®æ”¾å¤§å¤„ç†')
            elif pixels > 5000000:  # å¤§äº500ä¸‡åƒç´ 
                suggestions.append('å›¾ç‰‡å°ºå¯¸è¿‡å¤§ï¼Œå»ºè®®é€‚å½“ç¼©å°')
            
            # æ–‡æœ¬åŒºåŸŸé—®é¢˜
            text_regions = content.get('text_like_regions', 0)
            if text_regions == 0:
                suggestions.append('æœªæ£€æµ‹åˆ°æ˜æ˜¾æ–‡æœ¬åŒºåŸŸï¼Œå»ºè®®ä½¿ç”¨æ¿€è¿›é¢„å¤„ç†')
            elif text_regions > 50:
                suggestions.append('æ£€æµ‹åˆ°è¿‡å¤šæ–‡æœ¬åŒºåŸŸï¼Œå»ºè®®ä½¿ç”¨ROIè¿‡æ»¤')
            
            # è¾¹ç¼˜å¯†åº¦é—®é¢˜
            edge_density = quality.get('edge_density', 0)
            if edge_density < 0.01:
                suggestions.append('è¾¹ç¼˜ä¿¡æ¯ä¸è¶³ï¼Œå»ºè®®å¢å¼ºè¾¹ç¼˜')
            elif edge_density > 0.1:
                suggestions.append('è¾¹ç¼˜ä¿¡æ¯è¿‡å¤šï¼Œå»ºè®®é™å™ªå¤„ç†')
            
            if not suggestions:
                suggestions.append('å›¾ç‰‡è´¨é‡è‰¯å¥½ï¼Œä½¿ç”¨æ ‡å‡†é¢„å¤„ç†å³å¯')
                
        except Exception as e:
            suggestions.append(f'å»ºè®®ç”Ÿæˆå¤±è´¥: {e}')
        
        return suggestions
    
    def _assess_ocr_difficulty(self, analysis: Dict) -> str:
        """è¯„ä¼°OCRè¯†åˆ«éš¾åº¦"""
        try:
            quality = analysis.get('quality_metrics', {})
            content = analysis.get('content_analysis', {})
            
            # è®¡ç®—éš¾åº¦åˆ†æ•°
            difficulty_score = 0
            
            # äº®åº¦å› ç´ 
            brightness = quality.get('mean_brightness', 128)
            if brightness < 60 or brightness > 220:
                difficulty_score += 2
            elif brightness < 80 or brightness > 200:
                difficulty_score += 1
            
            # å¯¹æ¯”åº¦å› ç´ 
            contrast = quality.get('contrast', 50)
            if contrast < 20:
                difficulty_score += 2
            elif contrast < 30:
                difficulty_score += 1
            
            # æ¸…æ™°åº¦å› ç´ ï¼ˆæ›´ä¸¥æ ¼çš„è¯„ä¼°ï¼‰
            sharpness = quality.get('sharpness', 100)
            if sharpness < 50:  # é™ä½é˜ˆå€¼
                difficulty_score += 3  # å¢åŠ æƒé‡
            elif sharpness < 100:
                difficulty_score += 2
            
            # æ–‡æœ¬åŒºåŸŸå› ç´ 
            text_regions = content.get('text_like_regions', 0)
            if text_regions == 0:
                difficulty_score += 2
            elif text_regions > 100:
                difficulty_score += 1
            
            # è¾¹ç¼˜å¯†åº¦å› ç´ 
            edge_density = quality.get('edge_density', 0)
            if edge_density < 0.005:
                difficulty_score += 1
            
            # è¯„ä¼°éš¾åº¦ç­‰çº§ï¼ˆè°ƒæ•´é˜ˆå€¼ï¼‰
            if difficulty_score >= 5:  # é™ä½very_hardé˜ˆå€¼
                return 'very_hard'
            elif difficulty_score >= 3:  # é™ä½hardé˜ˆå€¼
                return 'hard'
            elif difficulty_score >= 1:  # é™ä½mediumé˜ˆå€¼
                return 'medium'
            else:
                return 'easy'
                
        except Exception as e:
            return 'unknown'
    
    def analyze_failed_file(self, image_path: str) -> Dict:
        """ä¸“é—¨åˆ†æOCRå¤±è´¥çš„æ–‡ä»¶"""
        print(f"\nğŸ” åˆ†æOCRå¤±è´¥æ–‡ä»¶: {os.path.basename(image_path)}")
        print("-" * 50)
        
        analysis = self.analyze_image(image_path)
        
        if 'error' in analysis:
            print(f"âŒ åˆ†æå¤±è´¥: {analysis['error']}")
            return analysis
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        basic = analysis['basic_info']
        quality = analysis['quality_metrics']
        content = analysis['content_analysis']
        
        print(f"ğŸ“ åŸºæœ¬ä¿¡æ¯:")
        print(f"   å°ºå¯¸: {basic['width']}x{basic['height']} ({basic['pixels']:,}åƒç´ )")
        print(f"   æ–‡ä»¶å¤§å°: {basic['file_size_mb']:.2f}MB")
        print(f"   å®½é«˜æ¯”: {basic['aspect_ratio']:.2f}")
        
        print(f"\nğŸ“Š è´¨é‡æŒ‡æ ‡:")
        print(f"   å¹³å‡äº®åº¦: {quality['mean_brightness']:.1f} (ç†æƒ³: 80-200)")
        print(f"   å¯¹æ¯”åº¦: {quality['contrast']:.1f} (ç†æƒ³: 30-100)")
        print(f"   æ¸…æ™°åº¦: {quality['sharpness']:.1f} (ç†æƒ³: >50)")
        print(f"   è¾¹ç¼˜å¯†åº¦: {quality['edge_density']:.3f} (ç†æƒ³: 0.01-0.1)")
        
        print(f"\nğŸ“ å†…å®¹åˆ†æ:")
        print(f"   æ–‡æœ¬åŒºåŸŸæ•°: {content['text_like_regions']}")
        print(f"   æ–‡æœ¬é¢ç§¯å æ¯”: {content['text_area_ratio']:.3f}")
        print(f"   äºŒå€¼åŒ–é˜ˆå€¼: {content['binary_threshold']}")
        
        print(f"\nğŸ¯ OCRéš¾åº¦: {analysis['ocr_difficulty']}")
        
        print(f"\nğŸ’¡ é¢„å¤„ç†å»ºè®®:")
        for i, suggestion in enumerate(analysis['preprocessing_suggestions'], 1):
            print(f"   {i}. {suggestion}")
        
        return analysis
    
    def get_optimization_strategy(self, analysis: Dict) -> str:
        """æ ¹æ®åˆ†æç»“æœæ¨èä¼˜åŒ–ç­–ç•¥"""
        if 'error' in analysis:
            return 'standard'
        
        difficulty = analysis.get('ocr_difficulty', 'medium')
        
        if difficulty == 'very_hard':
            return 'super_aggressive'
        elif difficulty == 'hard':
            return 'aggressive'
        elif difficulty == 'medium':
            return 'enhanced'
        else:
            return 'standard'
